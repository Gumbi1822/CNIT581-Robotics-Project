---
layout: post
title: Week 15 Final Demo Presentation
date: 2017-04-27
description: Week 15 progress report.
---
During the last week of the project Andrea and Mikaela had to pivot slightly to complete their objective of giving the user experience of looking into VR to see from the robot’s point of view. Rather than using C# with the Gear VR controller they decided to use the Raspberry Pi and Python with a keyboard to control the iRobot. They ran into connectivity issues with the controller because Andrea’s phone was updated to Android 8.0 Oreo. This updated caused several bugs to be shown in the Oculus API and thus created the controller to not have a reliable connection.

The camera feed was able to be successfully streamed to a static website using the motion library, but they were not able to use C# to fetch this website. They had to use the YouTube API v3 to embed the data to an .mp4 format and then stream that feed to a YouTube Live Stream video. This allowed them to see the video in a VR environment without the use of a 360 degree camera, which they didn’t have access to.

The video below shows a side by side comparison of a 2d video in a VR environment (on the right) and a 2d video that has been wrapped around the user (on the left). The YouTube API allows the content to be viewed in either perspective but for the purpose of this project the video on the right is the most practical approach for an immersion experience without the need for a 360 degree camera.

[![Final Demo Video](http://img.youtube.com/vi/s7OlYIO5Mao/0.jpg)](https://www.youtube.com/watch?v=s7OlYIO5Mao "Final Demo Video")
